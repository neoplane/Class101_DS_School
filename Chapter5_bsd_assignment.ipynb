{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Sharing Demand\n",
    "\n",
    "## 데이터분석과 시각화, 머신러닝 알고리즘으로 시간당 자전거 대여량을 예측하기\n",
    "\n",
    "(이 쥬피터 노트북은 다음의 링크 https://bit.ly/ds-bike-0101 에서 다운받을 수 있습니다.)\n",
    "\n",
    "이번 캐글 경진대회는 시간당 자전거 대여량을 예측하는 [Bike Sharing Demand](https://www.kaggle.com/c/bike-sharing-demand) 입니다. 워싱턴 D.C 소재의 자전거 대여 스타트업 [Capital Bikeshare](https://www.capitalbikeshare.com/)의 데이터를 활용하여, 특정 시간대에 얼마나 많은 사람들이 자전거를 대여하는지 예측하는 것이 목표입니다.\n",
    "\n",
    "사람들이 자전거를 대여하는데는 많은 요소가 관여되어 있을 겁니다. 가령 시간(새벽보다 낮에 많이 빌리겠죠), 날씨(비가 오면 자전거를 대여하지 않을 겁니다), 근무일(근무 시간에는 자전거를 대여하지 않겠죠) 등. 이런 모든 요소를 조합하여 워싱턴 D.C의 자전거 교통량을 예측해주세요. 이번 경진대회에서는 기존까지 배웠던 프로그래밍 언어와 인공지능&머신러닝 능력 외에도, 자전거 렌탈 시장에 대한 약간의 전문지식, 그리고 일반인의 기초 상식을 총동원 할 수 있습니다.\n",
    "\n",
    "저번 [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic/) 경진대회와 마찬가지로, 이번에도 프로그래밍 언어 파이썬([Python](https://www.python.org/)), 데이터 분석 패키지 판다스([Pandas](https://pandas.pydata.org/)), 그리고 머신러닝&인공지능 라이브러리인 싸이킷런([scikit-learn](scikit-learn.org))을 사용합니다. 여기에 더불어, 이번에는 데이터 시각화 패키지 [matplotlib](https://matplotlib.org/)와 [Seaborn](https://seaborn.pydata.org/)을 본격적으로 활용해볼 것입니다.\n",
    "\n",
    "## 컬럼 설명\n",
    "\n",
    "(데이터는 [다음의 링크](https://www.kaggle.com/c/bike-sharing-demand/data)에서 다운받으실 수 있습니다)\n",
    "\n",
    "  * **datetime** - 시간. 연-월-일 시:분:초 로 표현합니다. (가령 2011-01-01 00:00:00은 2011년 1월 1일 0시 0분 0초)\n",
    "  * **season** - 계절. 봄(1), 여름(2), 가을(3), 겨울(4) 순으로 표현합니다.\n",
    "  * **holiday** - 공휴일. 1이면 공휴일이며, 0이면 공휴일이 아닙니다.\n",
    "  * **workingday** - 근무일. 1이면 근무일이며, 0이면 근무일이 아닙니다.\n",
    "  * **weather** - 날씨. 1 ~ 4 사이의 값을 가지며, 구체적으로는 다음과 같습니다.\n",
    "    * 1: 아주 깨끗한 날씨입니다. 또는 아주 약간의 구름이 끼어있습니다.\n",
    "    * 2: 약간의 안개와 구름이 끼어있는 날씨입니다.\n",
    "    * 3: 약간의 눈, 비가 오거나 천둥이 칩니다.\n",
    "    * 4: 아주 많은 비가 오거나 우박이 내립니다.\n",
    "  * **temp** - 온도. 섭씨(Celsius)로 적혀있습니다.\n",
    "  * **atemp** - 체감 온도. 마찬가지로 섭씨(Celsius)로 적혀있습니다.\n",
    "  * **humidity** - 습도.\n",
    "  * **windspeed** - 풍속.\n",
    "  * **casual** - 비회원(non-registered)의 자전거 대여량.\n",
    "  * **registered** - 회원(registered)의 자전거 대여량.\n",
    "  * **count** - 총 자전거 대여랑. 비회원(casual) + 회원(registered)과 동일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬의 데이터 분석 패키지 Pandas(pandas.pydata.org) 를 읽어옵니다.\n",
    "# Pandas는 쉽게 말해 파이썬으로 엑셀을 다룰 수 있는 툴이라고 보시면 됩니다.\n",
    "# 이 패키지를 앞으로는 pd라는 축약어로 사용하겠습니다.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "언제나처럼 모든 데이터 분석의 시작은 주어진 데이터를 읽어오는 것입니다. [판다스(Pandas)](https://pandas.pydata.org/)의 [read_csv](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)를 활용하여 [Bike Sharing Demand](https://www.kaggle.com/c/bike-sharing-demand) 경진대회에서 제공하는 두 개의 데이터(train, test)를 읽어오겠습니다. ([다운로드 링크](https://www.kaggle.com/c/bike-sharing-demand/data))\n",
    "\n",
    "앞서 [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic/) 경진대회와 마찬가지로, 여기에서도 파일의 경로를 지정하는 방법에 주의하셔야 합니다. 만일 read_csv를 실행할 때 (**FileNotFoundError**)라는 이름의 에러가 난다면 경로가 제대로 지정이 되지 않은 것입니다. **파일의 경로를 지정하는 법이 생각나지 않는다면 [다음의 링크](http://88240.tistory.com/122)를 통해 경로를 지정하는 법을 복습한 뒤 다시 시도해주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10886, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n\n   humidity  windspeed  casual  registered  count  \n0        81        0.0       3          13     16  \n1        80        0.0       8          32     40  \n2        80        0.0       5          27     32  \n3        75        0.0       3          10     13  \n4        75        0.0       0           1      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>season</th>\n      <th>holiday</th>\n      <th>workingday</th>\n      <th>weather</th>\n      <th>temp</th>\n      <th>atemp</th>\n      <th>humidity</th>\n      <th>windspeed</th>\n      <th>casual</th>\n      <th>registered</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-01-01 00:00:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9.84</td>\n      <td>14.395</td>\n      <td>81</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>13</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-01-01 01:00:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9.02</td>\n      <td>13.635</td>\n      <td>80</td>\n      <td>0.0</td>\n      <td>8</td>\n      <td>32</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-01-01 02:00:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9.02</td>\n      <td>13.635</td>\n      <td>80</td>\n      <td>0.0</td>\n      <td>5</td>\n      <td>27</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-01-01 03:00:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9.84</td>\n      <td>14.395</td>\n      <td>75</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>10</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-01-01 04:00:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9.84</td>\n      <td>14.395</td>\n      <td>75</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here!\n",
    "train = pd.read_csv(\"input_ch5/train.csv\")\n",
    "\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10886, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n\n   humidity  windspeed  casual  registered  count  \n0        81        0.0       3          13     16  \n1        80        0.0       8          32     40  \n2        80        0.0       5          27     32  \n3        75        0.0       3          10     13  \n4        75        0.0       0           1      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>season</th>\n      <th>holiday</th>\n      <th>workingday</th>\n      <th>weather</th>\n      <th>temp</th>\n      <th>atemp</th>\n      <th>humidity</th>\n      <th>windspeed</th>\n      <th>casual</th>\n      <th>registered</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-01-01 00:00:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9.84</td>\n      <td>14.395</td>\n      <td>81</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>13</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-01-01 01:00:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9.02</td>\n      <td>13.635</td>\n      <td>80</td>\n      <td>0.0</td>\n      <td>8</td>\n      <td>32</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-01-01 02:00:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9.02</td>\n      <td>13.635</td>\n      <td>80</td>\n      <td>0.0</td>\n      <td>5</td>\n      <td>27</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-01-01 03:00:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9.84</td>\n      <td>14.395</td>\n      <td>75</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>10</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-01-01 04:00:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9.84</td>\n      <td>14.395</td>\n      <td>75</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"input_ch5/train.csv\")\n",
    "\n",
    "print(test.shape)\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "데이터를 읽어왔으면, 이 데이터를 편하게 분석하고 머신러닝 알고리즘에 집어넣기 위해 간단한 전처리(Preprocessing) 작업을 진행하겠습니다.\n",
    "\n",
    "[Bike Sharing Demand](https://www.kaggle.com/c/bike-sharing-demand)는 편리하게도 대부분의 데이터가 전처리 되어있습니다. (가령 season 컬럼은 봄을 spring이라 표현하지 않고 1이라고 표현합니다) 그러므로 [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic/) 경진대회와는 달리 간단한 전처리만 끝내면 바로 머신러닝 모델에 데이터를 집어넣을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse datetime\n",
    "\n",
    "먼저 **날짜(datetime)** 컬럼을 전처리 하겠습니다.\n",
    "\n",
    "날짜 컬럼은 얼핏 보면 여러개의 숫자로 구성되어 있습니다. (ex: 2011-01-01 00:00:00) 하지만 결론적으로 숫자는 아니며, 판다스에서는 문자열(object) 또는 날짜(datetime64)로 인식합니다. (값에 하이픈(-)과 콜론(:)이 있기 때문입니다) 그러므로 날짜(datetime) 컬럼을 사용하기 위해서는 머신러닝 알고리즘이 이해할 수 있는 방식으로 전처리를 해줘야 합니다.\n",
    "\n",
    "날짜(datetime) 컬럼을 전처리하는 가장 쉬운 방법은 연, 월, 일, 시, 분, 초를 따로 나누는 것입니다. 가령 2011-01-01 00:00:00은 2011년 1월 1일 0시 0분 0초라고 볼 수 있으므로, 2011, 1, 1, 0, 0, 0으로 따로 나누면 총 6개의 숫자가 됩니다. 즉, **날짜(datetime) 컬럼을 여섯개의 다른 컬럼으로 나누어주는 것이 날짜 컬럼을 전처리하는 핵심입니다**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore\n",
    "\n",
    "전처리(Preprocesing)를 끝냈으면 그 다음에는 데이터를 분석해보겠습니다.\n",
    "\n",
    "주어진 데이터를 시각화나 분석 툴을 통해 다양한 관점에서 이해하는 과정을 탐험적 데이터 분석([Exploratory Data Analysis](https://en.wikipedia.org/wiki/Exploratory_data_analysis))이라고 합니다. 저번 타이타닉 문제와 마찬가지로, 이번에도 파이썬의 데이터 시각화 패키지인 ([matplotlib](https://matplotlib.org))와 [seaborn](https://seaborn.pydata.org/) 을 활용해서 분석해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib로 실행하는 모든 시각화를 자동으로 쥬피터 노트북에 띄웁니다.\n",
    "# seaborn 도 결국에는 matplotlib를 기반으로 동작하기 때문에, seaborn으로 실행하는 모든 시각화도 마찬가지로 쥬피터 노트북에 자동적으로 띄워집니다.\n",
    "%matplotlib inline\n",
    "\n",
    "# 데이터 시각화 패키지 seaborn을 로딩합니다. 앞으로는 줄여서 sns라고 사용할 것입니다.\n",
    "import seaborn as sns\n",
    "\n",
    "# 데이터 시각화 패키지 matplotlib를 로딩합니다. 앞으로는 줄여서 plt라고 사용할 것입니다.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datetime\n",
    "\n",
    "먼저 분석할 컬럼은 **날짜(datetime)** 컬럼입니다. 날짜 컬럼은 [Bike Sharing Demand](https://www.kaggle.com/c/bike-sharing-demand) 경진대회의 핵심 컬럼이라고 볼 수 있으며, 이번 경진대회에서 상위 성적을 올리고 싶다면 날짜 컬럼을 완벽하게 이해하는 것이 무엇보다도 중요합니다.\n",
    "\n",
    "먼저 연/월/일/시/분/초에 따른 자전거 대여량을 시각화 해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1-1) 시각화를 하기 전에 어떤 그림이 나올 것으로 예상하시나요? 최소 3가지 아이디어를 생각해보세요.\n",
    "\n",
    "**주의**: 이 내용은 반드시 **시각화를 하기 전에 작성하셔야 합니다.** 그래야 시각화 결과와 본인의 아이디어를 비교해서 차이를 발견할 수 있습니다.\n",
    "\n",
    "1. 일단 분(```Dates-minute```), 초(```Dates-second```)는 자전거 대여량을 판가름하는데 별 영향이 없을 것 같습니다. 가령 현재 시간이 37분이면 자전거를 대여하고, 43분이면 자전거를 대여하지 않는 행동을 하지는 않을 것입니다. 그러므로 countplot으로 시각화를 해보면, 마치 [Uniform Distribution](https://m.blog.naver.com/running_p/90179231685)과 같은 모양이 나올 것 같습니다.\n",
    "\n",
    "1. 그리고 일(```Dates-day```)도 비슷합니다. 하지만 일(```Dates-day```)은 분과 초와는 다르게, 1) 2월에는 28일 이후가 존재하지 않기 때문에, 29, 30, 31일은 다른 날보다 데이터가 적을 수도 있습니다. (예외적으로 2012년은 2월 29일이 있습니다), 비슷하게 2) 31일의 경우에는 다른 날에 비해 데이터가 절반밖에 되지 않을 것입니다. 하지만 우리는 데이터의 갯수보다는 날짜별 자전거의 평균 대여량이 중요하기 때문에, 실제 분석에는 큰 영향을 미치지 않을 것으로 예상합니다.\n",
    "\n",
    "1. 이런 사항 외에도, 사람의 행동 패턴 상으로 날짜나 시간이라는 개념이 자전거를 대여하는데 중요한 영향을 미칠 것 같습니다. 가령 1) 시간(hour)을 기준으로 새벽보다는 오후에 사람들이 자전거를 많이 빌릴것이며, 2) 월(month)을 기준으로 추운 여름보다는 따뜻한 봄이나 가을, 내지는 더운 여름이 더 많이 빌릴 것 같습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자, 그럼 위 예상과 실제 데이터가 일치하는지 데이터 시각화를 통해 살펴보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1-2) 이 시각화로 발견할 수 있는 사실은 어떤 게 있을까요? 그리고 앞서 우리의 예상과 어떤 차이가 있나요?\n",
    "\n",
    "**datetime-year**\n",
    "  * 2011년도의 자전거 대여량보다 2012년도의 자전거 대여량이 더 높습니다. 이는 [Bike Sharing Demand](https://www.kaggle.com/c/bike-sharing-demand) 경진대회를 주최한 [Capital Bikeshare](https://www.capitalbikeshare.com/)사가 꾸준히 성장하고 있다고 간주할 수 있습니다.\n",
    "\n",
    "**datetime-month**\n",
    "  * 주로 여름(6\\~8월)에 자전거를 많이 빌리며, 겨울(12\\~2월)에는 자전거를 많이 빌리지 않습니다.\n",
    "  * 같은 겨울이라도 12월의 자전거 대여량이 1월의 자전거 대여량보다 두 배 가까이 높아 보입니다. 하지만 여기에는 숨겨진 비밀이 있는데, 다음에 나올 다른 시각화에서 자세히 살펴보겠습니다.\n",
    "  \n",
    "**datetime-day**\n",
    "  * x축을 자세히 보면 1일부터 19일까지밖에 없습니다. 20일은 어디에 있을까요? 바로 test 데이터에 있습니다. 이 시각화에서 알 수 있는 내용은, train 데이터와 test 데이터를 나누는 기준이 되는 컬럼이 바로 ```datetime-day```라는 것입니다. 그러므로 21일 이후의 자전거 대여량에 대해서는 우리도 알 수 없고, 머신러닝 알고리즘도 알지 못할 것입니다.\n",
    "\n",
    "**datetime-hour**\n",
    "  * 새벽 시간에는 사람들이 자전거를 빌리지 않으며, 오후 시간에 상대적으로 자전거를 많이 빌립니다.\n",
    "  * 특이하게도 두 부분에서 사람들이 자전거를 특별히 많이 빌리는 현상이 있습니다. 바로 출근 시간(7\\~9시)과 퇴근 시간(16시\\~19시) 입니다.\n",
    "  * 물론 출퇴근시간이 아닌 다른 시간대에 자전거를 빌리는 경우도 존재합니다. 이는 다음에 나올 다른 시각화에서 자세히 살펴보겠습니다.\n",
    "\n",
    "**datetime-minute** & **datetime-second**\n",
    "  * 이 두 컬럼은 x축이 모두 0으로 되어있습니다. 즉, **datetime-minute**과 **datetime-second**은 기록되고 있지 않다는 사실을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자, 이제 더 중요한 사실에 대해서 고민해 보도록 하겠습니다.\n",
    "\n",
    "우리에게 중요한건 데이터에 어떤 특징이 있는지 발견하는 것도 있지만, **이 특징을 활용해 앞으로 사용할 머신러닝 알고리즘을 개선시킬 수 있는가?**가 더 중요합니다. 또한 개선을 한다면 구체적으로 어떤 방식으로 개선하는지도 중요하겠죠."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1-3) 이 사실을 통해 어떻게 예측 모델을 개선할 수 있을까요? 최소 3가지 아이디어를 내보세요.\n",
    "\n",
    "1. 먼저 분(```datetime-minute```)과 초(```datetime-second```)는 기록되지 않기 때문에 굳이 사용할 필요가 없을 것 같습니다. 차후에 머신러닝 알고리즘에 적용할 때, 이 부분은 feature에서 제거해도 될 것 같습니다.\n",
    "2. 앞서 설명한대로, train 데이터와 test 데이터를 나누는 기준이 되는 컬럼이 바로 일(```datetime-day```) 컬럼입니다. 이런 경우 **datetime-day**를 feature로 집어넣으면 머신러닝 알고리즘이 과적합([overfitting](https://hyperdot.wordpress.com/2017/02/06/%EA%B3%BC%EC%A0%81%ED%95%A9overfitting/)) 되는 현상이 일어날 수 있습니다. 그러므로 train 데이터와 test 데이터를 나누는 기준이 되는 컬럼이 있으면, 이 컬럼은 feature로 사용하지 않는 것이 좋을 것 같습니다.\n",
    "3. 이외에도 시(```datetime-hour```)컬럼을 보면 출퇴근시간에 사람들이 자전거를 많이 빌린다는 사실을 알 수 있습니다. 그렇다면, 만일 머신러닝 알고리즘이 출퇴근시간이라는 개념을 이해하지 못한다고 하면 이를 별도의 feature로 넣어주면 성능 향상을 꾀할 수 있을 듯 합니다. (다만 아쉽게도, ```workingday```라는 컬럼이 이 역할을 대신하고 있을 것입니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weather 컬럼 분석\n",
    "\n",
    "그 다음 분석하고 싶은 컬럼은 날씨를 나타내는 ```weather``` 컬럼입니다. 이 컬럼을 다음의 값을 가지며, 구체적인 설명은 다음과 같습니다.\n",
    "\n",
    "  * 1: 아주 깨끗한 날씨입니다. 또는 아주 약간의 구름이 끼어있습니다.\n",
    "  * 2: 약간의 안개와 구름이 끼어있는 날씨입니다.\n",
    "  * 3: 약간의 눈, 비가 오거나 천둥이 칩니다.\n",
    "  * 4: 아주 많은 비가 오거나 우박이 내립니다.\n",
    "\n",
    "이 데이터를 엑셀 분석, 내지는 시각화하여 weather에 따라 자전거 대여량이 어떻게 변하는지 살펴보도록 하겠습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-1) 시각화를 하기 전에 어떤 그림이 나올 것으로 예상하시나요? 최소 3가지 아이디어를 생각해보세요.\n",
    "\n",
    "**주의**: 이 내용은 반드시 **시각화를 하기 전에 작성하셔야 합니다.** 그래야 시각화 결과와 본인의 아이디어를 비교해서 차이를 발견할 수 있습니다.\n",
    "\n",
    "1. 일단 당연하지만 안 좋은 날씨일수록 자전거 대여량이 낮아질 것 같습니다. 1(깨끗한 날씨)의 경우보다 4(아주 많은 비나 우박이 오는 날씨)인 경우에 자전거를 덜 빌릴 것입니다.\n",
    "2. 그리고 값이 숫자(1, 2, 3, 4)로 되어있지만, 실제로는 수의 높고 낮은 관계가 존재하지 않을 것입니다. (이를 전문용어로 연속형(continuous) 데이터 vs 범주형(categorical) 데이터라고 합니다) 그러므로 보이는 것과는 다르게, 실제로는 범주형(categorical) 데이터로 처리해야 할 것입니다.\n",
    "3. 아주 심하진 않겠지만, 날씨마다의 편차가 있을 것입니다. 가령 어떤 날은 날씨가 좋아도 안 빌리고, 어떤 날은 날씨가 안 좋아도 많이 빌릴 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에도 위 예상과 실제 데이터가 일치하는지 데이터 시각화를 통해 살펴보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-2) 이 시각화로 발견할 수 있는 사실은 어떤 게 있을까요? 그리고 앞서 우리의 예상과 어떤 차이가 있나요?\n",
    "\n",
    "1. 앞서 생각한대로 날씨(```weather```)가 안 좋을수록 자전거 대여량이 낮아지는 현상을 발견할 수 있었습니다. 즉, 날씨(```weather```)값이 3보다 2가, 2보다 1이 더 자전거를 많이 빌리는 현상이 보입니다.\n",
    "2. 하지만 굉장히 특이하게도 날씨가 4인 경우, 즉 아주 많은 비가 오거나 우박이 내리는 경우에 자전거를 많이 빌리는 현상이 보입니다. 심지어는 날씨가 2인 경우(약간의 안개나 구름)에 못지 않게 자전거를 많이 빌리는 사실을 알 수 있습니다.\n",
    "3. 그리고 시각화에서 신뢰 구간(confidence interval)을 상징하는 검은색 세로 선이 날씨가 4인 경우에는 보이지 않습니다. 추측컨데 날씨가 4인 경우에는 일반적인 분포와는 다소 다른 현상이 일어나고 있다고 판단할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-3) 이 사실을 통해 어떻게 예측 모델을 개선할 수 있을까요? 최소 3가지 아이디어를 내보세요.\n",
    "\n",
    "1. 날씨(```weather```) 컬럼값이 1 ~ 3인 것만 봤을 때, 이 컬럼을 머신러닝 알고리즘에 feature로 넣으면 우리가 별도의 룰을 설정해주지 않아도 머신러닝 알고리즘이 알아서 날씨(```weather```)에 따른 자전거 대여량의 변화량을 예측할 수 있을 것 같습니다. 아마도 날씨가 좋을 수록(1에 가까울수록) 자전거를 많이 빌리고, 안 좋을수록(3에 가까울수록) 자전거를 덜 빌릴 것 같습니다.\n",
    "1. **<<여러분들이 스스로 고민한 뒤 아이디어를 적어주세요>>**\n",
    "1. **<<여러분들이 스스로 고민한 뒤 아이디어를 적어주세요>>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### windspeed 컬럼 분석\n",
    "\n",
    "그 다음 분석하고 싶은 컬럼은 날씨를 나타내는 풍속을 나타내는 ```windspeed``` 컬럼입니다. 이 컬럼은 0에서 56까지의 값을 가집니다. 이 데이터도 시각화 해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3-1) 시각화를 하기 전에 어떤 그림이 나올 것으로 예상하시나요? 최소 3가지 아이디어를 생각해보세요.\n",
    "\n",
    "1. 이 데이터는 연속형(continuous) 자료이므로 분포를 시각화하면 전형적인 [정규 분포](https://ko.wikipedia.org/wiki/%EC%A0%95%EA%B7%9C_%EB%B6%84%ED%8F%AC)가 나올 것입니다.\n",
    "2. 하지만 이 데이터는 현실 세계의 데이터이기 때문에, 이론처럼 완벽한 정규 분포가 나오지는 않을 것입니다. 아마도 추측컨데 1) 몇몇 아웃라이어가 존재하거나, 2) 바람이 특별하게 많이 불어서 분포의 오른쪽이 길게 늘어지는 현상이 생길 것 같습니다.\n",
    "3. 그리고 추측컨데 바람이 너무 많이 불면 사람들이 자전거를 덜 빌릴 것으로 예상합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 예상과 실제 데이터가 일치하는지 다시 한 번 살펴보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3-2) 이 시각화로 발견할 수 있는 사실은 어떤 게 있을까요? 그리고 앞서 우리의 예상과 어떤 차이가 있나요?\n",
    "\n",
    "1. 분포는 전반적으로 정규 분포가 나오지만, 1) 값이 연속적(continuous)이지 않고 듬성듬성 떨어져 있습니다. 즉, 이 데이터는 연속형(continuous) 데이터가 아닌 범주형(categorical) 데이터에 가까워 보입니다.\n",
    "2. 더 특이한건, 풍속이 0인 경우가 굉장히 많으며, 정규 분포가 이상하게 보일 정도로 비중이 높습니다.\n",
    "3. 또한 풍속이 과하게 높을수록 자전거를 덜 빌리는 현상이 보이는 것 같은데, 이는 전반적으로 모수가 부족한 듯 하여 신뢰도가 높지 않습니다. 다만 풍속이 낮을 경우에 전반적으로 자전거 대여량이 낮은 현상이 보입니다. (이는 우리가 예상하지 못한 현상입니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3-3) 이 사실을 통해 어떻게 예측 모델을 개선할 수 있을까요? 최소 3가지 아이디어를 내보세요.\n",
    "\n",
    "1. 이 풍속(windspeed) 데이터를 머신러닝 알고리즘에 집어넣으면 머신러닝 알고리즘의 풍속에 따른 자전거 대여량의 변화를 스스로 판단할 수 있을 것 같습니다. 더 정확히는, 풍속이 낮거나 높을수록 자전거를 덜 빌리고, 풍속이 적당할 때 자전거를 더 많이 빌린다는 사실을 알 수 있습니다.\n",
    "1. **<<여러분들이 스스로 고민한 뒤 아이디어를 적어주세요>>**\n",
    "1. **<<여러분들이 스스로 고민한 뒤 아이디어를 적어주세요>>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temp\n",
    "\n",
    "이번에 분석할 데이터는 온도(```temp```) 컬럼입니다. 여기서부터는 제가 직접 하지 않고, 여러분들을 위한 과제로 제공하겠습니다. 앞서 컬럼들을 분석했던 것 처럼, 온도(```temp```) 컬럼도 직접 분석해보세요. \n",
    "\n",
    "힌트: 온도(```temp```) 컬럼만으로 좋은 분석 결과가 나오지 않는다면, 체감온도(```atemp```)를 포함한 다른 컬럼을 활용하여 시각화해보세요. 시각화는 [lmplot](https://seaborn.pydata.org/generated/seaborn.lmplot.html?highlight=lmplot#seaborn.lmplot)이나 [scatterplot](https://seaborn.pydata.org/generated/seaborn.scatterplot.html?highlight=scatterplot#seaborn.scatterplot)을 사용하면 직관적인 시각화를 할 수 있을 것입니다. (단 ```scatterplot```은 seaborn의 버전이 낮으면 실행되지 않으니 이 점 주의해주세요. 이 경우는 버전을 업그레이드 한 뒤 사용하시면 됩니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4-1) 온도(```temp```) 컬럼을 시각화 하기 전에 어떤 그림이 나올 것으로 예상하시나요?\n",
    "주의: 이 내용은 반드시 시각화를 하기 전에 작성하셔야 합니다. 그래야 시각화 결과와 본인의 아이디어를 비교해서 차이를 발견할 수 있습니다.\n",
    "\n",
    "1. **<<여러분들이 스스로 고민한 뒤 아이디어를 적어주세요>>**\n",
    "1. **<<여러분들이 스스로 고민한 뒤 아이디어를 적어주세요>>**\n",
    "1. **<<여러분들이 스스로 고민한 뒤 아이디어를 적어주세요>>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temp 컬럼 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4-2) 이 시각화로 발견할 수 있는 사실은 어떤 게 있을까요? 그리고 앞서 우리의 예상과 어떤 차이가 있나요?\n",
    "\n",
    "1. **<<첫 번째 예상과 일치하는지 여부를 상세히 적어주세요>>**\n",
    "2. **<<두 번째 예상과 일치하는지 여부를 상세히 적어주세요>>**\n",
    "3. **<<세 번째 예상과 일치하는지 여부를 상세히 적어주세요>>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4-3) 이 사실을 통해 어떻게 예측 모델을 개선할 수 있을까요? 최소 3가지 아이디어를 내보세요.\n",
    "1. **<<여러분들이 스스로 고민한 뒤 아이디어를 적어주세요>>**\n",
    "1. **<<여러분들이 스스로 고민한 뒤 아이디어를 적어주세요>>**\n",
    "1. **<<여러분들이 스스로 고민한 뒤 아이디어를 적어주세요>>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나머지 데이터를 시각화를 통해 더 분석하기\n",
    "\n",
    "지금까지 분석한 결과 외에도 다양한 방식으로 데이터를 분석하거나 시각화하여 데이터를 더 깊게 이해할려는 시도를 할 수 있습니다. 아직 우리는 분석하지 않은 다양한 데이터(```season```, ```holiday```, ```workingday```, ```humidity```, etc)가 있으며, 이 데이터에서 우리가 기존에 발견하지 못한 (내지는 머신러닝도 스스로 발견하지 못하는) 힌트를 발견할 수 있습니다.\n",
    "\n",
    "몇몇 힌트를 드리자면\n",
    "\n",
    "  * 체감 온도(```atemp```)라는게 구체적으로 어떤 개념인지 한 번 고민해보세요. 체감온도를 측정하기 위해서 자전거를 대여하는 사람의 몸에다가 일일이 센서를 붙일 수 없습니다. 분명 다른 방식으로 체감 온도를 측정하거나 계산하고 있을 것입니다.\n",
    "  * 또한 비슷하게, 비회원(```casual```)과 회원(```registered```)이 어떤 의미인지 한 번 고민해보세요. 일반적으로 자전거 대여량을 측정할 때 이렇게 디테일하게 측정하지 않을 것입니다. (=분명 다른 이유가 있기 때문에 이런 방식으로 측정할 것 같습니다)\n",
    "  * 그리고 위 컬럼이 아닌, 완전 새로운 개념에 해당하는 컬럼을 추가한 뒤 이를 feature로 사용하는 것도 가능합니다. 가령 1) 날짜 데이터를 갖고 있다면 우리는 요일(dayofweek) 정보를 뽑아낼 수 있고, 2) 온도(```temp```)와 습도(```humidity```)를 알고 있다면 우리는 불쾌지수(discomfort index)를 계산할 수 있습니다. 이러한 정보들을 머신러닝 알고리즘에 적용하면 머신러닝이 새로운 정보를 알 수 있을 것입니다.\n",
    "  * 다만 데이터를 분석하거나 시각화 할 때, 처음에는 label(맞춰야 하는 정답)을 기준으로 분석하는 것이 효율적이라는 점을 유의해주세요. 시각화를 할 때도 x, y, hue 중에 가능한 한 축을 ```count```컬럼으로 놓고 분석하는 것이 유리합니다.\n",
    "  * 그리고 비슷한 이유로, 다른 모든 컬럼보다 ```count```컬럼을 완벽하게 분석하고 이해하는 것이 중요합니다. ```count```의 전반적인 분포와 최소/최대치, 그리고 ```casual```과 ```registered```의 관계 등을 집중적으로 분석해주세요.\n",
    "  \n",
    "  \n",
    "위의 힌트, 또는 본인이 생각하기에 중요하다고 생각되는 부분을 분석해보세요. 주어진 형식에 구애받지 않고 자유롭게 데이터를 분석하면 됩니다. 하지만 분석에 과정에서 몇몇 도움이 되는 노하우를 공유하자면\n",
    "\n",
    "  * 위의 힌트를 포함한 대부분은 구글에서 검색하면 쉽게 찾을 수 있습니다. 가령 1) 체감 온도(```atemp```)의 개념과 이를 측정 또는 계산하는 방식, 2) 판다스(Pandas)를 활용해 날짜 데이터에서 요일(dayofweek) 정보를 뽑는 법 등등. 대부분의 노하우들은 인터넷에 이미 존재합니다. 이를 빠르게 검색해서 내 코드에 적용하는 것도 데이터 사이언티스트들의 중요한 소양이자 실력입니다.\n",
    "  * 정보를 얻을 때, 창의성도 중요하지만 유사 솔루션, 경진대회, 데이터셋을 벤치마킹하는 실력도 매우 중요합니다. 캐글에서는 보통 [Kernel](https://www.kaggle.com/c/bike-sharing-demand/kernels) 탭에서 사람들이 본인들만의 분석 결과와 솔루션을 올리고, [Discussion](https://www.kaggle.com/c/bike-sharing-demand/discussion) 탭에서 경진대회에 대한 토론을 합니다. 이 탭을 집중적으로 살펴보고 벤치마킹 해주세요. 심지어 [이런](https://www.kaggle.com/viveksrinivasan/eda-ensemble-model-top-10-percentile/notebook) 페이지에는 경진대회 상위 10%에 도달하는 노하우가 그대로 공유되어 있습니다. 이 노하우만 잘 이해해도 충분합니다.\n",
    "  * 그리고 비슷하게, [Bike Sharing Demand](https://www.kaggle.com/c/bike-sharing-demand) 경진대회의 다양한 솔루션들을 구글에서 찾을 수도 있습니다. [다음의 링크](https://www.analyticsvidhya.com/blog/2015/06/solution-kaggle-competition-bike-sharing-demand/)나 [다음의 링크](https://medium.com/@viveksrinivasan/how-to-finish-top-10-percentile-in-bike-sharing-demand-competition-in-kaggle-part-1-c816ea9c51e1)처럼 이 경진대회에 대해 자세히 분석하고 솔루션을 제시하는 곳도 있습니다. 이런 솔루션을 구글에서 찾아서 적극적으로 벤치마킹 해주세요.\n",
    "  * 마지막으로, 데이터는 많이 분석하면 분석할수록 노하우가 쌓입니다. 그리고 캐글 경진대회도 많이 참여할수록 점점 노하우가 쌓이게 됩니다. 그런 의미에서, 이전에 참여한 경진대회에서 먹혔던 분석 노하우가 전략을 적극적으로 활용해보세요. 가령 [Titanic](https://www.kaggle.com/c/titanic) 경진대회에서 먹혔던 전략을 그대로 활용하는 것도 가능합니다.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수고 많으셨습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}